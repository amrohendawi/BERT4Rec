{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5d72db-cf32-49af-9356-cfb0181c38d0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Demo for BERT4Rec from scratch\n",
    "\n",
    "In this notebook we demonstrate how to train a `BERT4Rec` model from scratch, including preparing a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35a8d5a-b794-4c29-91d6-9024a845648c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Create runtime environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f748d042-a9b6-448c-9594-434ce159f9f7",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed PyYAML-6.0 colorama-0.4.4 colorlog-4.7.2 joblib-1.2.0 markdown-3.4.1 pandas-1.4.4 pillow-9.3.0 protobuf-3.19.6 pytz-2022.6 recbole-1.0.1 scikit-learn-1.1.3 scipy-1.6.0 torch-1.12.1+cu116 torchaudio-0.12.1+cu116 torchvision-0.13.1+cu116 tqdm-4.64.1 typing-extensions-4.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.4.1 requires jinja2, which is not installed.\n",
      "-bash: line 1: python: command not found\n",
      "-bash: line 2: venv/bin/activate: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://download.pytorch.org/whl/cu116/torch_stable.html\n",
      "Requirement already satisfied: recbole~=1.0.1 in /home/lazerdance/.local/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: torch==1.12.1+cu116 in /home/lazerdance/.local/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.12.1+cu116)\n",
      "Requirement already satisfied: torchaudio==0.12.1+cu116 in /home/lazerdance/.local/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.12.1+cu116)\n",
      "Requirement already satisfied: torchvision==0.13.1+cu116 in /home/lazerdance/.local/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (0.13.1+cu116)\n",
      "Requirement already satisfied: numpy~=1.23.2 in /home/lazerdance/.local/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.23.4)\n",
      "Requirement already satisfied: pandas~=1.4.4 in /home/lazerdance/.local/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: tqdm~=4.64.1 in /home/lazerdance/.local/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (4.64.1)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/lazerdance/.local/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (6.0)\n",
      "Requirement already satisfied: typing-extensions in /home/lazerdance/.local/lib/python3.8/site-packages (from torch==1.12.1+cu116->-r requirements.txt (line 2)) (4.4.0)\n",
      "Requirement already satisfied: requests in /home/lazerdance/.local/lib/python3.8/site-packages (from torchvision==0.13.1+cu116->-r requirements.txt (line 4)) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/lazerdance/.local/lib/python3.8/site-packages (from torchvision==0.13.1+cu116->-r requirements.txt (line 4)) (9.3.0)\n",
      "Requirement already satisfied: colorlog==4.7.2 in /home/lazerdance/.local/lib/python3.8/site-packages (from recbole~=1.0.1->-r requirements.txt (line 1)) (4.7.2)\n",
      "Requirement already satisfied: colorama==0.4.4 in /home/lazerdance/.local/lib/python3.8/site-packages (from recbole~=1.0.1->-r requirements.txt (line 1)) (0.4.4)\n",
      "Requirement already satisfied: scipy==1.6.0 in /home/lazerdance/.local/lib/python3.8/site-packages (from recbole~=1.0.1->-r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23.2 in /home/lazerdance/.local/lib/python3.8/site-packages (from recbole~=1.0.1->-r requirements.txt (line 1)) (1.1.3)\n",
      "Requirement already satisfied: tensorboard>=2.5.0 in /home/lazerdance/.local/lib/python3.8/site-packages (from recbole~=1.0.1->-r requirements.txt (line 1)) (2.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/lazerdance/.local/lib/python3.8/site-packages (from pandas~=1.4.4->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/lazerdance/.local/lib/python3.8/site-packages (from pandas~=1.4.4->-r requirements.txt (line 6)) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas~=1.4.4->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/lazerdance/.local/lib/python3.8/site-packages (from scikit-learn>=0.23.2->recbole~=1.0.1->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/lazerdance/.local/lib/python3.8/site-packages (from scikit-learn>=0.23.2->recbole~=1.0.1->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/lazerdance/.local/lib/python3.8/site-packages (from tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (3.19.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/lazerdance/.local/lib/python3.8/site-packages (from tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (2.13.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (0.37.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (59.6.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/lazerdance/.local/lib/python3.8/site-packages (from tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/lazerdance/.local/lib/python3.8/site-packages (from tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/lazerdance/.local/lib/python3.8/site-packages (from tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/lazerdance/.local/lib/python3.8/site-packages (from tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/lazerdance/.local/lib/python3.8/site-packages (from tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/lazerdance/.local/lib/python3.8/site-packages (from tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (1.50.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/lazerdance/.local/lib/python3.8/site-packages (from tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/lazerdance/.local/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu116->-r requirements.txt (line 4)) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/lazerdance/.local/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu116->-r requirements.txt (line 4)) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lazerdance/.local/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu116->-r requirements.txt (line 4)) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lazerdance/.local/lib/python3.8/site-packages (from requests->torchvision==0.13.1+cu116->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/lazerdance/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/lazerdance/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/lazerdance/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/lazerdance/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/lib/python3/dist-packages (from markdown>=2.6.8->tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (4.6.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/lazerdance/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/lazerdance/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/lazerdance/.local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.5.0->recbole~=1.0.1->-r requirements.txt (line 1)) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff9a4f-0bd2-43f8-9196-ca2915435772",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c37d75e-4d57-4362-81e2-8d72d6696952",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Download and unpack the chosen dataset inside the datasets directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6305063f-bae2-47b4-8cf7-79a0e36c6e52",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-11-21 12:34:14--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4924029 (4.7M) [application/zip]\n",
      "Saving to: ‘ml-100k.zip’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1%  203K 23s\n",
      "    50K .......... .......... .......... .......... ..........  2%  399K 17s\n",
      "   100K .......... .......... .......... .......... ..........  3% 34.2M 12s\n",
      "   150K .......... .......... .......... .......... ..........  4%  399K 11s\n",
      "   200K .......... .......... .......... .......... ..........  5% 38.0M 9s\n",
      "   250K .......... .......... .......... .......... ..........  6% 9.86M 8s\n",
      "   300K .......... .......... .......... .......... ..........  7%  415K 8s\n",
      "   350K .......... .......... .......... .......... ..........  8% 26.9M 7s\n",
      "   400K .......... .......... .......... .......... ..........  9% 13.8M 6s\n",
      "   450K .......... .......... .......... .......... .......... 10% 33.1M 5s\n",
      "   500K .......... .......... .......... .......... .......... 11% 25.5M 5s\n",
      "   550K .......... .......... .......... .......... .......... 12% 9.07M 4s\n",
      "   600K .......... .......... .......... .......... .......... 13% 23.5M 4s\n",
      "   650K .......... .......... .......... .......... .......... 14%  454K 4s\n",
      "   700K .......... .......... .......... .......... .......... 15% 35.8M 4s\n",
      "   750K .......... .......... .......... .......... .......... 16% 30.6M 4s\n",
      "   800K .......... .......... .......... .......... .......... 17% 32.6M 4s\n",
      "   850K .......... .......... .......... .......... .......... 18% 11.2M 3s\n",
      "   900K .......... .......... .......... .......... .......... 19% 34.5M 3s\n",
      "   950K .......... .......... .......... .......... .......... 20% 31.9M 3s\n",
      "  1000K .......... .......... .......... .......... .......... 21% 27.2M 3s\n",
      "  1050K .......... .......... .......... .......... .......... 22% 36.0M 3s\n",
      "  1100K .......... .......... .......... .......... .......... 23% 41.8M 2s\n",
      "  1150K .......... .......... .......... .......... .......... 24% 21.2M 2s\n",
      "  1200K .......... .......... .......... .......... .......... 25% 16.6M 2s\n",
      "  1250K .......... .......... .......... .......... .......... 27%  482K 2s\n",
      "  1300K .......... .......... .......... .......... .......... 28% 26.5M 2s\n",
      "  1350K .......... .......... .......... .......... .......... 29% 14.3M 2s\n",
      "  1400K .......... .......... .......... .......... .......... 30% 20.1M 2s\n",
      "  1450K .......... .......... .......... .......... .......... 31% 34.2M 2s\n",
      "  1500K .......... .......... .......... .......... .......... 32% 27.7M 2s\n",
      "  1550K .......... .......... .......... .......... .......... 33% 38.7M 2s\n",
      "  1600K .......... .......... .......... .......... .......... 34% 36.5M 2s\n",
      "  1650K .......... .......... .......... .......... .......... 35% 25.4M 2s\n",
      "  1700K .......... .......... .......... .......... .......... 36% 29.0M 2s\n",
      "  1750K .......... .......... .......... .......... .......... 37% 7.25M 2s\n",
      "  1800K .......... .......... .......... .......... .......... 38% 36.1M 1s\n",
      "  1850K .......... .......... .......... .......... .......... 39% 31.9M 1s\n",
      "  1900K .......... .......... .......... .......... .......... 40% 33.7M 1s\n",
      "  1950K .......... .......... .......... .......... .......... 41% 37.7M 1s\n",
      "  2000K .......... .......... .......... .......... .......... 42% 14.0M 1s\n",
      "  2050K .......... .......... .......... .......... .......... 43% 20.2M 1s\n",
      "  2100K .......... .......... .......... .......... .......... 44% 22.6M 1s\n",
      "  2150K .......... .......... .......... .......... .......... 45% 14.2M 1s\n",
      "  2200K .......... .......... .......... .......... .......... 46% 24.8M 1s\n",
      "  2250K .......... .......... .......... .......... .......... 47% 14.6M 1s\n",
      "  2300K .......... .......... .......... .......... .......... 48% 21.2M 1s\n",
      "  2350K .......... .......... .......... .......... .......... 49% 22.0M 1s\n",
      "  2400K .......... .......... .......... .......... .......... 50% 8.92M 1s\n",
      "  2450K .......... .......... .......... .......... .......... 51% 34.6M 1s\n",
      "  2500K .......... .......... .......... .......... .......... 53% 28.9M 1s\n",
      "  2550K .......... .......... .......... .......... .......... 54% 14.6M 1s\n",
      "  2600K .......... .......... .......... .......... .......... 55%  729K 1s\n",
      "  2650K .......... .......... .......... .......... .......... 56% 33.3M 1s\n",
      "  2700K .......... .......... .......... .......... .......... 57% 38.4M 1s\n",
      "  2750K .......... .......... .......... .......... .......... 58% 39.5M 1s\n",
      "  2800K .......... .......... .......... .......... .......... 59% 6.04M 1s\n",
      "  2850K .......... .......... .......... .......... .......... 60% 44.0M 1s\n",
      "  2900K .......... .......... .......... .......... .......... 61% 32.7M 1s\n",
      "  2950K .......... .......... .......... .......... .......... 62% 38.8M 1s\n",
      "  3000K .......... .......... .......... .......... .......... 63% 41.2M 1s\n",
      "  3050K .......... .......... .......... .......... .......... 64% 14.7M 1s\n",
      "  3100K .......... .......... .......... .......... .......... 65% 21.5M 1s\n",
      "  3150K .......... .......... .......... .......... .......... 66% 21.5M 1s\n",
      "  3200K .......... .......... .......... .......... .......... 67% 15.0M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 68% 39.2M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 69% 30.8M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 70% 13.9M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 71% 35.4M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 72% 27.3M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 73% 31.0M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 74% 14.0M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 75% 24.8M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 76% 11.0M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 77% 32.3M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 79% 35.1M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 80%  375K 0s\n",
      "  3850K .......... .......... .......... .......... .......... 81% 26.3M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 82% 33.0M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 83% 32.3M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 84% 35.9M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 85% 28.2M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 86% 29.1M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 87% 33.2M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 88% 31.2M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 89% 4.06M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 90% 24.1M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 91% 16.9M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 92% 30.1M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 93% 32.0M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 94% 27.6M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 95% 32.4M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 96% 35.0M 0s\n",
      "  4650K .......... .......... .......... .......... .......... 97% 31.0M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 98% 28.2M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 99% 30.2M 0s\n",
      "  4800K ........                                              100% 15.4M=1.2s\n",
      "\n",
      "2022-11-21 12:34:16 (3.80 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-100k.zip\n",
      "   creating: ml-100k/\n",
      "  inflating: ml-100k/allbut.pl       \n",
      "  inflating: ml-100k/mku.sh          \n",
      "  inflating: ml-100k/README          \n",
      "  inflating: ml-100k/u.data          \n",
      "  inflating: ml-100k/u.genre         \n",
      "  inflating: ml-100k/u.info          \n",
      "  inflating: ml-100k/u.item          \n",
      "  inflating: ml-100k/u.occupation    \n",
      "  inflating: ml-100k/u.user          \n",
      "  inflating: ml-100k/u1.base         \n",
      "  inflating: ml-100k/u1.test         \n",
      "  inflating: ml-100k/u2.base         \n",
      "  inflating: ml-100k/u2.test         \n",
      "  inflating: ml-100k/u3.base         \n",
      "  inflating: ml-100k/u3.test         \n",
      "  inflating: ml-100k/u4.base         \n",
      "  inflating: ml-100k/u4.test         \n",
      "  inflating: ml-100k/u5.base         \n",
      "  inflating: ml-100k/u5.test         \n",
      "  inflating: ml-100k/ua.base         \n",
      "  inflating: ml-100k/ua.test         \n",
      "  inflating: ml-100k/ub.base         \n",
      "  inflating: ml-100k/ub.test         \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p datasets && cd datasets\n",
    "\n",
    "if [ ! -f ml-100k.zip ]; then\n",
    "wget http://files.grouplens.org/datasets/movielens/ml-100k.zip;\n",
    "unzip ml-100k.zip;\n",
    "rm ml-100k.zip\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ff8f7e-631e-47be-b939-8f80b98bf23c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Preprocess the downloaded dataset to the atomic format that the RecSys models understand.\n",
    "\n",
    "The following command converts the raw dataset into the necessary atomic-formatted files:\n",
    "- interactions\n",
    "- items\n",
    "- users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10ca3f8f-e0fd-4e45-87cb-b5136ff96690",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:04<00:00, 22814.22it/s]\n",
      "100%|██████████| 1682/1682 [00:00<00:00, 22982.11it/s]\n",
      "100%|██████████| 943/943 [00:00<00:00, 19741.10it/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 preprocess_dataset.py --dataset ml-100k  --convert_inter --convert_item --convert_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35766694-84e7-481a-b61e-053a3df0b8fc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Prepare config file\n",
    "\n",
    "Prepare a config.yaml file with the chosen dataset, model, hyperparameters and so on. You can copy one of the example config files in the `config` folder and adjust it to fit your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a645c6-f603-4a0d-a1fb-b1e174bcc33b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5ce1c4a-24ef-407b-90bd-8240c60909a3",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "command line args [--model_name BERT4Rec --config config_ml-100k.yaml] will not be used in RecBole\n",
      "21 Nov 12:38    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /home/lazerdance/.local/lib/python3.8/site-packages/recbole/config/../dataset_example/ml-100k\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 10\n",
      "train_batch_size = 3500\n",
      "learner = adam\n",
      "learning_rate = 0.01\n",
      "neg_sampling = None\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [4, 1, 1]}, 'group_by': 'None', 'order': 'TO', 'mode': 'uni50'}\n",
      "repeatable = True\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision', 'MAP']\n",
      "topk = [12]\n",
      "valid_metric = MAP@12\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 3500\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = None\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp'], 'user': ['user_id'], 'item': ['item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = False\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "n_layers = 4\n",
      "n_heads = 4\n",
      "hidden_size = 64\n",
      "inner_size = 256\n",
      "hidden_dropout_prob = 0.5\n",
      "attn_dropout_prob = 0.5\n",
      "hidden_act = gelu\n",
      "layer_norm_eps = 1e-12\n",
      "initializer_range = 0.02\n",
      "mask_ratio = 0.2\n",
      "loss_type = CE\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'by', 'by': 50, 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "21 Nov 12:38    INFO  ml-100k\n",
      "The number of users: 944\n",
      "Average actions of users: 106.04453870625663\n",
      "The number of items: 1683\n",
      "Average actions of items: 59.45303210463734\n",
      "The number of inters: 100000\n",
      "The sparsity of the dataset: 93.70575143257098%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
      "21 Nov 12:38    INFO  [Training]: train_batch_size = [3500] negative sampling: [None]\n",
      "21 Nov 12:38    INFO  [Evaluation]: eval_batch_size = [3500] eval_args: [{'split': {'RS': [4, 1, 1]}, 'group_by': 'None', 'order': 'TO', 'mode': 'uni50'}]\n",
      "21 Nov 12:38    INFO  BERT4Rec(\n",
      "  (item_embedding): Embedding(1684, 64, padding_idx=0)\n",
      "  (position_embedding): Embedding(51, 64)\n",
      "  (trm_encoder): TransformerEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0): TransformerLayer(\n",
      "        (multi_head_attention): MultiHeadAttention(\n",
      "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
      "          (dense): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (dense_1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dense_2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): TransformerLayer(\n",
      "        (multi_head_attention): MultiHeadAttention(\n",
      "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
      "          (dense): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (dense_1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dense_2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): TransformerLayer(\n",
      "        (multi_head_attention): MultiHeadAttention(\n",
      "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
      "          (dense): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (dense_1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dense_2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): TransformerLayer(\n",
      "        (multi_head_attention): MultiHeadAttention(\n",
      "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
      "          (dense): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (dense_1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dense_2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Trainable parameters: 311104\n",
      "2022-11-21 12:38:07.768276: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-21 12:38:08.221858: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-21 12:38:09.066008: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-21 12:38:09.066119: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-21 12:38:09.066138: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Train     0: 100%|██████████████████████████| 19/19 [00:27<00:00,  1.43s/it, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:38    INFO  epoch 0 training [time: 27.18s, train loss: 129.5398]\n",
      "Evaluate   : 100%|████████████████████████| 250/250 [01:25<00:00,  2.93it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:40    INFO  epoch 0 evaluating [time: 85.22s, valid_score: 0.214000]\n",
      "21 Nov 12:40    INFO  valid result: \n",
      "recall@12 : 0.0944    mrr@12 : 0.4648    ndcg@12 : 0.3116    hit@12 : 0.776    precision@12 : 0.281    map@12 : 0.214\n",
      "21 Nov 12:40    INFO  Saving current: saved/BERT4Rec-Nov-21-2022_12-38-10.pth\n",
      "Train     1: 100%|██████████████████████████| 19/19 [00:17<00:00,  1.11it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:40    INFO  epoch 1 training [time: 17.07s, train loss: 127.1573]\n",
      "Evaluate   : 100%|████████████████████████| 250/250 [01:28<00:00,  2.82it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:41    INFO  epoch 1 evaluating [time: 88.66s, valid_score: 0.128700]\n",
      "21 Nov 12:41    INFO  valid result: \n",
      "recall@12 : 0.0911    mrr@12 : 0.3029    ndcg@12 : 0.2104    hit@12 : 0.652    precision@12 : 0.1917    map@12 : 0.1287\n",
      "Train     2: 100%|██████████████████████████| 19/19 [00:15<00:00,  1.23it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:42    INFO  epoch 2 training [time: 15.50s, train loss: 127.0633]\n",
      "Evaluate   : 100%|████████████████████████| 250/250 [01:28<00:00,  2.83it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:43    INFO  epoch 2 evaluating [time: 88.42s, valid_score: 0.182100]\n",
      "21 Nov 12:43    INFO  valid result: \n",
      "recall@12 : 0.0956    mrr@12 : 0.4386    ndcg@12 : 0.283    hit@12 : 0.752    precision@12 : 0.2547    map@12 : 0.1821\n",
      "Train     3: 100%|██████████████████████████| 19/19 [00:15<00:00,  1.25it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:43    INFO  epoch 3 training [time: 15.24s, train loss: 126.7433]\n",
      "Evaluate   : 100%|████████████████████████| 250/250 [01:20<00:00,  3.09it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:45    INFO  epoch 3 evaluating [time: 80.81s, valid_score: 0.156000]\n",
      "21 Nov 12:45    INFO  valid result: \n",
      "recall@12 : 0.0809    mrr@12 : 0.4125    ndcg@12 : 0.2518    hit@12 : 0.688    precision@12 : 0.2243    map@12 : 0.156\n",
      "Train     4: 100%|██████████████████████████| 19/19 [00:13<00:00,  1.38it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:45    INFO  epoch 4 training [time: 13.82s, train loss: 126.9447]\n",
      "Evaluate   : 100%|████████████████████████| 250/250 [01:20<00:00,  3.12it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:46    INFO  epoch 4 evaluating [time: 80.03s, valid_score: 0.233100]\n",
      "21 Nov 12:46    INFO  valid result: \n",
      "recall@12 : 0.1423    mrr@12 : 0.542    ndcg@12 : 0.3605    hit@12 : 0.856    precision@12 : 0.3163    map@12 : 0.2331\n",
      "21 Nov 12:46    INFO  Saving current: saved/BERT4Rec-Nov-21-2022_12-38-10.pth\n",
      "Train     5: 100%|██████████████████████████| 19/19 [00:13<00:00,  1.42it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:46    INFO  epoch 5 training [time: 13.37s, train loss: 126.9281]\n",
      "Evaluate   : 100%|████████████████████████| 250/250 [01:24<00:00,  2.96it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:48    INFO  epoch 5 evaluating [time: 84.37s, valid_score: 0.187700]\n",
      "21 Nov 12:48    INFO  valid result: \n",
      "recall@12 : 0.094    mrr@12 : 0.4741    ndcg@12 : 0.2927    hit@12 : 0.728    precision@12 : 0.2607    map@12 : 0.1877\n",
      "Train     6: 100%|██████████████████████████| 19/19 [00:16<00:00,  1.13it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:48    INFO  epoch 6 training [time: 16.78s, train loss: 126.8603]\n",
      "Evaluate   : 100%|████████████████████████| 250/250 [01:36<00:00,  2.60it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:50    INFO  epoch 6 evaluating [time: 96.09s, valid_score: 0.182900]\n",
      "21 Nov 12:50    INFO  valid result: \n",
      "recall@12 : 0.0985    mrr@12 : 0.4832    ndcg@12 : 0.2927    hit@12 : 0.772    precision@12 : 0.258    map@12 : 0.1829\n",
      "Train     7: 100%|██████████████████████████| 19/19 [00:16<00:00,  1.12it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:50    INFO  epoch 7 training [time: 16.93s, train loss: 126.8830]\n",
      "Evaluate   : 100%|████████████████████████| 250/250 [01:16<00:00,  3.27it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:51    INFO  epoch 7 evaluating [time: 76.44s, valid_score: 0.144800]\n",
      "21 Nov 12:51    INFO  valid result: \n",
      "recall@12 : 0.0787    mrr@12 : 0.4285    ndcg@12 : 0.2482    hit@12 : 0.732    precision@12 : 0.2167    map@12 : 0.1448\n",
      "Train     8: 100%|██████████████████████████| 19/19 [00:13<00:00,  1.42it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:52    INFO  epoch 8 training [time: 13.40s, train loss: 126.5035]\n",
      "Evaluate   : 100%|████████████████████████| 250/250 [01:18<00:00,  3.18it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:53    INFO  epoch 8 evaluating [time: 78.55s, valid_score: 0.124600]\n",
      "21 Nov 12:53    INFO  valid result: \n",
      "recall@12 : 0.0716    mrr@12 : 0.4063    ndcg@12 : 0.2239    hit@12 : 0.684    precision@12 : 0.202    map@12 : 0.1246\n",
      "Train     9: 100%|██████████████████████████| 19/19 [00:13<00:00,  1.40it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:53    INFO  epoch 9 training [time: 13.60s, train loss: 125.8754]\n",
      "Evaluate   : 100%|████████████████████████| 250/250 [01:23<00:00,  3.00it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:54    INFO  epoch 9 evaluating [time: 83.20s, valid_score: 0.122600]\n",
      "21 Nov 12:54    INFO  valid result: \n",
      "recall@12 : 0.0718    mrr@12 : 0.4186    ndcg@12 : 0.2239    hit@12 : 0.676    precision@12 : 0.1973    map@12 : 0.1226\n",
      "21 Nov 12:54    INFO  Loading model structure and parameters from saved/BERT4Rec-Nov-21-2022_12-38-10.pth\n",
      "Evaluate   : 100%|████████████████████████| 241/241 [01:24<00:00,  2.86it/s, GPU RAM: 6.85 G/8.00 G]\n",
      "21 Nov 12:56    INFO  best valid : OrderedDict([('recall@12', 0.1423), ('mrr@12', 0.542), ('ndcg@12', 0.3605), ('hit@12', 0.856), ('precision@12', 0.3163), ('map@12', 0.2331)])\n",
      "21 Nov 12:56    INFO  test result: OrderedDict([('recall@12', 0.1316), ('mrr@12', 0.5628), ('ndcg@12', 0.3726), ('hit@12', 0.8755), ('precision@12', 0.3347), ('map@12', 0.2343)])\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 run.py --model_name BERT4Rec --config config_ml-100k.yaml --dataset=ml-100k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6811ef40-de83-44ca-ac07-a3adc78243e0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Congratulations! You just trained a BERT4Rec model on a dataset of your choice. The model and the dataset are stored in the `saved` folder as `.path` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca6b57f4-7664-480b-90fe-759450131182",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/amroh/Desktop/Master Thesis/Crawlers/recommender_systems\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip freeze > full_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}